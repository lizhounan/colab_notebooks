{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepDream.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPZPf9cmaZfX4gFaXj11zXF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SOkdjtJx2Qy","executionInfo":{"status":"ok","timestamp":1611011739700,"user_tz":300,"elapsed":47655,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"57c4cca8-2027-41c1-f37b-35c164fba3da"},"source":["!pip install tensorflow-gpu"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/aa/ae64be5acaac9055329289e6bfd54c1efa28bfe792f9021cea495fe2b89d/tensorflow_gpu-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl (394.7MB)\n","\u001b[K     |████████████████████████████████| 394.7MB 44kB/s \n","\u001b[?25hRequirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.32.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.19.5)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.36.2)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.4.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.4.3)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow-gpu) (51.1.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (3.3.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.7.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.4.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.17.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.3.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2020.12.5)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (1.3.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.4.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.4.8)\n","Installing collected packages: tensorflow-gpu\n","Successfully installed tensorflow-gpu-2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HoZ85IoQgIXS","executionInfo":{"status":"ok","timestamp":1611011760726,"user_tz":300,"elapsed":2176,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["import tensorflow as tf\r\n","from tensorflow.keras.layers import *\r\n","import tensorflow.keras.backend as K\r\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\r\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WBUT0ebwl0-G","executionInfo":{"status":"ok","timestamp":1611011778425,"user_tz":300,"elapsed":4229,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"b153a7ad-7d4f-4e7e-b5d8-0eab93b25360"},"source":["model = InceptionV3(include_top=False, weights='imagenet')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87916544/87910968 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UH9G9tbpmR5O"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFK_pkI3qtbT","executionInfo":{"status":"ok","timestamp":1611011793223,"user_tz":300,"elapsed":375,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["import scipy\r\n","from tensorflow.keras.preprocessing import image\r\n","from tensorflow.keras.applications import inception_v3\r\n","def resize_img(img, size):\r\n","    img = np.copy(img)\r\n","    factors = (1,\r\n","               float(size[0]) / img.shape[1],\r\n","               float(size[1]) / img.shape[2],\r\n","               1)\r\n","    return scipy.ndimage.zoom(img, factors, order=1)\r\n","\r\n","\r\n","def save_img(img, fname):\r\n","    pil_img = deprocess_image(np.copy(img))\r\n","    scipy.misc.imsave(fname, pil_img)\r\n","\r\n","\r\n","def preprocess_image(image_path):\r\n","    # Util function to open, resize and format pictures\r\n","    # into appropriate tensors.\r\n","    img = image.load_img(image_path)\r\n","    img = image.img_to_array(img)\r\n","    img = np.expand_dims(img, axis=0)\r\n","    img = inception_v3.preprocess_input(img)\r\n","    return img\r\n","\r\n","\r\n","def deprocess_image(x):\r\n","    # Util function to convert a tensor into a valid image.\r\n","    if K.image_data_format() == 'channels_first':\r\n","        x = x.reshape((3, x.shape[2], x.shape[3]))\r\n","        x = x.transpose((1, 2, 0))\r\n","    else:\r\n","        x = x.reshape((x.shape[1], x.shape[2], 3))\r\n","    x /= 2.\r\n","    x += 0.5\r\n","    x *= 255.\r\n","    x = np.clip(x, 0, 255).astype('uint8')\r\n","    return x"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"jBbix-EFqx6c","executionInfo":{"status":"ok","timestamp":1611014977398,"user_tz":300,"elapsed":390,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["import numpy as np\r\n","\r\n","# Playing with these hyperparameters will also allow you to achieve new effects\r\n","\r\n","step = 0.01  # Gradient ascent step size\r\n","num_octave = 3  # Number of scales at which to run gradient ascent\r\n","octave_scale = 1.4  # Size ratio between scales\r\n","iterations = 20  # Number of ascent steps per scale\r\n","\r\n","# If our loss gets larger than 10,\r\n","# we will interrupt the gradient ascent process, to avoid ugly artifacts\r\n","max_loss = 10.\r\n","\r\n","# Fill this to the path to the image you want to use\r\n","base_image_path = '/content/1.jpg'\r\n","\r\n","# Load the image into a Numpy array\r\n","img = preprocess_image(base_image_path)\r\n","\r\n","# We prepare a list of shape tuples\r\n","# defining the different scales at which we will run gradient ascent\r\n","original_shape = img.shape[1:3]\r\n","successive_shapes = [original_shape]\r\n","for i in range(1, num_octave):\r\n","    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\r\n","    successive_shapes.append(shape)\r\n","\r\n","# Reverse list of shapes, so that they are in increasing order\r\n","successive_shapes = successive_shapes[::-1]\r\n","\r\n","# Resize the Numpy array of the image to our smallest scale\r\n","original_img = np.copy(img)\r\n","shrunk_original_img = resize_img(img, successive_shapes[0])\r\n","\r\n"],"execution_count":113,"outputs":[]},{"cell_type":"code","metadata":{"id":"7s8jth8NohOV","executionInfo":{"status":"ok","timestamp":1611011831065,"user_tz":300,"elapsed":530,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["layer_weights = [0.2, 3.0, 2.0, 1.5]\r\n","layer_list = ['mixed2', 'mixed3', 'mixed4', 'mixed5']"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xox3VrNs3dTs"},"source":["### **test one step gradient ascent**\r\n"]},{"cell_type":"markdown","metadata":{"id":"cWoWohxX374s"},"source":["**make a input tensor: tf variablr initialized by shrunk_original_img**"]},{"cell_type":"code","metadata":{"id":"u9mE3x_Creq1","executionInfo":{"status":"ok","timestamp":1611014402086,"user_tz":300,"elapsed":811,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["shrunk_original_img = tf.Variable(initial_value = shrunk_original_img)"],"execution_count":87,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jpMfD-Cg73Fr"},"source":["build a new model to get the output of those layers"]},{"cell_type":"code","metadata":{"id":"eYIeywc-72r0","executionInfo":{"status":"ok","timestamp":1611014500984,"user_tz":300,"elapsed":616,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["dream_model = tf.keras.Model(model.input, [model.get_layer(layer).output for layer in layer_list])"],"execution_count":99,"outputs":[]},{"cell_type":"code","metadata":{"id":"VuTj3qpb71R5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3TU6CHiJ4Goe"},"source":["**build grad tape**"]},{"cell_type":"code","metadata":{"id":"vmzozqMcysZo","executionInfo":{"status":"ok","timestamp":1611014534293,"user_tz":300,"elapsed":610,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["with tf.GradientTape(persistent=True) as tape:\r\n","    loss = tf.constant(0.0)\r\n","    tape.watch(shrunk_original_img)\r\n","    outputs = dream_model(shrunk_original_img)\r\n","    for i, o in enumerate(outputs):\r\n","        # print(type(o))   # is it possible that the reason of ' the tape is broken '  is that the type of those values is 'np.darray'?\r\n","        scaling = K.prod(K.cast(K.shape(o), 'float32'))\r\n","        loss += layer_weights[i] * K.sum(K.square(o[:, 2: -2, 2: -2, :])) / scaling"],"execution_count":100,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3YLhEM_tzi-e","executionInfo":{"status":"ok","timestamp":1611014535985,"user_tz":300,"elapsed":424,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"fd9cef0e-9376-4845-e313-96fa38e6c665"},"source":["loss"],"execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=1.6337845>"]},"metadata":{"tags":[]},"execution_count":101}]},{"cell_type":"markdown","metadata":{"id":"AXcCKZ-f4LlO"},"source":["**compute grads**"]},{"cell_type":"code","metadata":{"id":"Q71WEvQvzc6l","executionInfo":{"status":"ok","timestamp":1611014538284,"user_tz":300,"elapsed":1102,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["grads = tape.gradient(loss, shrunk_original_img)"],"execution_count":102,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HwM1-17w0kpS","executionInfo":{"status":"ok","timestamp":1611014540152,"user_tz":300,"elapsed":895,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"0a28b991-0c0f-4482-bbb5-71d654c83812"},"source":["print(grads)"],"execution_count":103,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[[[-2.3837952e-06  1.5734507e-06 -7.8990792e-07]\n","   [-3.4992504e-06  4.7754834e-06 -1.0679682e-06]\n","   [ 3.6564850e-06  8.3603827e-06 -1.5219522e-06]\n","   ...\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n","\n","  [[-1.3711244e-06  3.2263338e-06 -1.4987492e-06]\n","   [ 8.2639480e-07  9.3457211e-06 -1.1410708e-06]\n","   [ 2.7219692e-06  7.6256574e-06 -2.7848919e-06]\n","   ...\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n","\n","  [[ 5.4563588e-06  4.5083175e-06 -1.7950000e-06]\n","   [ 5.7759848e-06  5.7993770e-06 -4.2263532e-06]\n","   [ 4.7469598e-06  3.3259362e-06 -2.7874096e-06]\n","   ...\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n","\n","  ...\n","\n","  [[-1.5850527e-07  4.3354154e-07 -1.9741981e-07]\n","   [-9.4550700e-08 -3.2340117e-07 -6.4074464e-07]\n","   [-5.7447460e-07 -1.4955006e-06 -1.1762797e-06]\n","   ...\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n","\n","  [[-1.4989693e-07  2.2493688e-07 -2.6450343e-07]\n","   [-2.8644749e-07 -2.4260739e-08 -4.9855413e-07]\n","   [-7.3892988e-07 -1.9100092e-07 -3.2998855e-07]\n","   ...\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n","\n","  [[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   ...\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]]]], shape=(1, 244, 434, 3), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uiHgJz8l3t6E"},"source":["### **deep dreaming**"]},{"cell_type":"code","metadata":{"id":"KA_zR18Q86vI","executionInfo":{"status":"ok","timestamp":1611014634644,"user_tz":300,"elapsed":773,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["dream_model = tf.keras.Model(model.input, [model.get_layer(layer).output for layer in layer_list])"],"execution_count":104,"outputs":[]},{"cell_type":"code","metadata":{"id":"bydvI9Epu5Cs","executionInfo":{"status":"ok","timestamp":1611014637903,"user_tz":300,"elapsed":716,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["def fetch_loss_and_grads(img):\r\n","    with tf.GradientTape() as tape:\r\n","        loss = 0\r\n","        img = tf.Variable(img)\r\n","        outputs = dream_model(img)\r\n","        for i, o in enumerate(outputs):\r\n","            # We avoid border artifacts by only involving non-border pixels in the loss.\r\n","            scaling = K.prod(K.cast(K.shape(o), 'float32'))\r\n","            loss += layer_weights[i] * K.sum(K.square(o[:, 2: -2, 2: -2, :])) / scaling\r\n","    \r\n","    grads = tape.gradient(loss, img)[0]\r\n","    grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)\r\n","    outputs = [loss, grads]\r\n","    return outputs"],"execution_count":105,"outputs":[]},{"cell_type":"code","metadata":{"id":"kpSqhMy_or6n","executionInfo":{"status":"ok","timestamp":1611014643046,"user_tz":300,"elapsed":449,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["def eval_loss_and_grads(x):\r\n","    outs = fetch_loss_and_grads(x)\r\n","    loss_value = outs[0]\r\n","    grad_values = outs[1]\r\n","    return loss_value, grad_values\r\n","\r\n","def gradient_ascent(x, iterations, step, max_loss=None):\r\n","    for i in range(iterations):\r\n","        loss_value, grad_values = eval_loss_and_grads(x)\r\n","        if max_loss is not None and loss_value > max_loss:\r\n","            break\r\n","        print('...Loss value at', i, ':', loss_value)\r\n","        x += step * grad_values\r\n","    return x"],"execution_count":106,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OUiqe84SrO62","executionInfo":{"status":"ok","timestamp":1611015018623,"user_tz":300,"elapsed":36398,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"a7053bc0-c395-40b1-d60b-ea2d68a72608"},"source":["for shape in successive_shapes:\r\n","    print('Processing image shape', shape)\r\n","    img = resize_img(img, shape)\r\n","    tensor_img = tf.Variable(img)\r\n","    img = gradient_ascent(img, iterations=iterations, step=step, max_loss=max_loss)\r\n","    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\r\n","    same_size_original = resize_img(original_img, shape)\r\n","    lost_detail = same_size_original - upscaled_shrunk_original_img\r\n","\r\n","    img += lost_detail\r\n","    shrunk_original_img = resize_img(original_img, shape)\r\n","    # save_img(img, fname='dream_at_scale_' + str(shape) + '.png')\r\n","#"],"execution_count":114,"outputs":[{"output_type":"stream","text":["Processing image shape (244, 434)\n","...Loss value at 0 : tf.Tensor(1.6337845, shape=(), dtype=float32)\n","...Loss value at 1 : tf.Tensor(2.0448835, shape=(), dtype=float32)\n","...Loss value at 2 : tf.Tensor(2.6504216, shape=(), dtype=float32)\n","...Loss value at 3 : tf.Tensor(3.2228754, shape=(), dtype=float32)\n","...Loss value at 4 : tf.Tensor(3.865238, shape=(), dtype=float32)\n","...Loss value at 5 : tf.Tensor(4.5367727, shape=(), dtype=float32)\n","...Loss value at 6 : tf.Tensor(5.242536, shape=(), dtype=float32)\n","...Loss value at 7 : tf.Tensor(5.885832, shape=(), dtype=float32)\n","...Loss value at 8 : tf.Tensor(6.4866176, shape=(), dtype=float32)\n","...Loss value at 9 : tf.Tensor(7.1043987, shape=(), dtype=float32)\n","...Loss value at 10 : tf.Tensor(7.674169, shape=(), dtype=float32)\n","...Loss value at 11 : tf.Tensor(8.289647, shape=(), dtype=float32)\n","...Loss value at 12 : tf.Tensor(8.802347, shape=(), dtype=float32)\n","...Loss value at 13 : tf.Tensor(9.415799, shape=(), dtype=float32)\n","...Loss value at 14 : tf.Tensor(9.95938, shape=(), dtype=float32)\n","Processing image shape (342, 608)\n","...Loss value at 0 : tf.Tensor(2.7931178, shape=(), dtype=float32)\n","...Loss value at 1 : tf.Tensor(4.0761895, shape=(), dtype=float32)\n","...Loss value at 2 : tf.Tensor(5.214102, shape=(), dtype=float32)\n","...Loss value at 3 : tf.Tensor(6.265991, shape=(), dtype=float32)\n","...Loss value at 4 : tf.Tensor(7.283028, shape=(), dtype=float32)\n","...Loss value at 5 : tf.Tensor(8.435412, shape=(), dtype=float32)\n","...Loss value at 6 : tf.Tensor(9.768303, shape=(), dtype=float32)\n","Processing image shape (480, 852)\n","...Loss value at 0 : tf.Tensor(3.659574, shape=(), dtype=float32)\n","...Loss value at 1 : tf.Tensor(5.84835, shape=(), dtype=float32)\n","...Loss value at 2 : tf.Tensor(8.727058, shape=(), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jr7JSOdjqbQm","executionInfo":{"status":"ok","timestamp":1611015047831,"user_tz":300,"elapsed":462,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["pil_img = deprocess_image(np.copy(img))"],"execution_count":115,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JrTSF-VL92VF","executionInfo":{"status":"ok","timestamp":1611015049166,"user_tz":300,"elapsed":406,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"acf5e65b-e512-4703-c6c1-4fc8aafb54c6"},"source":["pil_img.shape"],"execution_count":116,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(480, 852, 3)"]},"metadata":{"tags":[]},"execution_count":116}]},{"cell_type":"code","metadata":{"id":"Il0c3s7g9-15","executionInfo":{"status":"ok","timestamp":1611015052131,"user_tz":300,"elapsed":404,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["from PIL import Image\r\n","img = Image.fromarray(pil_img, 'RGB')\r\n","img.save('my.png')\r\n","img.show()"],"execution_count":117,"outputs":[]},{"cell_type":"code","metadata":{"id":"2x1qtfoD-OCF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aGAjzmJS-Q22"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]}]}