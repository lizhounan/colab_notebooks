{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lavender_CV.ipynb","provenance":[],"collapsed_sections":["eHPSdEkVeyIr"],"toc_visible":true,"mount_file_id":"11NI6jYIq5veCFn4gCBbZrUdFAPYorBGK","authorship_tag":"ABX9TyNN2r1fRYRqKoNjjb/ULM8X"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"GaBH2ELIOhqv","executionInfo":{"status":"ok","timestamp":1608610842636,"user_tz":300,"elapsed":872,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["import pandas as pd\r\n","import numpy as np\r\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"NDWcD8eyYigR","executionInfo":{"status":"ok","timestamp":1608610852871,"user_tz":300,"elapsed":9498,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["df = pd.read_pickle('/content/drive/MyDrive/cv_fulldata_dec2020.pkl')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"FcPHuY8gYmNl","executionInfo":{"status":"ok","timestamp":1608610870503,"user_tz":300,"elapsed":766,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"be492b9a-770e-44be-c16c-dd8130bea271"},"source":["df.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>anger</th>\n","      <th>fear</th>\n","      <th>joy</th>\n","      <th>none</th>\n","      <th>sadness</th>\n","      <th>uncertain</th>\n","      <th>url</th>\n","      <th>tag</th>\n","      <th>visual_f</th>\n","      <th>tag_f</th>\n","      <th>feature</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5h47LBNpbb6TAvl41O</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>https://giphy.com/gifs/Generali-Deutschland-in...</td>\n","      <td>{'movies': 0, 'tv': 0, 'cartoons &amp; comics': 0,...</td>\n","      <td>[0.04423453470916779, 0.009959404213202556, 0....</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>N4K0mbaJtwLgQ</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>https://giphy.com/gifs/no-john-oliver-N4K0mbaJ...</td>\n","      <td>{'movies': 0, 'tv': 0, 'cartoons &amp; comics': 0,...</td>\n","      <td>[0.03488446688546817, 0.013676315889161121, 0....</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>moXqsEVbHOQtG</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>https://giphy.com/gifs/black-and-white-dog-moX...</td>\n","      <td>{'movies': 0, 'tv': 0, 'cartoons &amp; comics': 0,...</td>\n","      <td>[0.012639926140571394, 0.019328883207623205, 0...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>l2JJHiitHbK0hnbXO</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>https://giphy.com/gifs/syfy-sharks-sharknado-l...</td>\n","      <td>{'movies': 0, 'tv': 0, 'cartoons &amp; comics': 0,...</td>\n","      <td>[0.020821025840194362, 0.020494779066882123, 0...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>3oEduQ3FsAU0YD1Gec</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>https://giphy.com/gifs/rupaulsdragraces5-tv-sh...</td>\n","      <td>{'movies': 0, 'tv': 0, 'cartoons &amp; comics': 0,...</td>\n","      <td>[0.03954229882019586, 0.011084108204927126, 0....</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              content  ...                                            feature\n","0  5h47LBNpbb6TAvl41O  ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","1       N4K0mbaJtwLgQ  ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","3       moXqsEVbHOQtG  ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","4   l2JJHiitHbK0hnbXO  ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","5  3oEduQ3FsAU0YD1Gec  ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n","\n","[5 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"Kezu6QT7cB7b"},"source":["from PIL import Image\r\n","from PIL import ImageSequence\r\n","img = Image.open(\"/content/drive/MyDrive/giphy.gif\")\r\n","i = 0\r\n","for frame in ImageSequence.Iterator(img):\r\n","    frame.save(\"frame%d.png\" % i)\r\n","    i += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZBqsBTRc3dZ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eHPSdEkVeyIr"},"source":["# **build i3d**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cvMTMGSZe17r","executionInfo":{"elapsed":3529,"status":"ok","timestamp":1608523776959,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"},"user_tz":300},"outputId":"d07dc2cd-fe9b-4a7a-d806-3d42c42284fe"},"source":["!pip install dm-sonnet"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting dm-sonnet\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/28/9185afffefb655ef1a29f4b84aa9f656826408ca2d1b9ffeba81fbfd40ec/dm_sonnet-2.0.0-py3-none-any.whl (254kB)\n","\r\u001b[K     |█▎                              | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20kB 22.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 30kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 40kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 51kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 61kB 13.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 71kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 81kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 92kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 102kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 112kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 122kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 133kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 143kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 153kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 163kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 174kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 184kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 194kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 204kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 215kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 225kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 235kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 245kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256kB 12.5MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from dm-sonnet) (1.15.0)\n","Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from dm-sonnet) (0.10.0)\n","Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.6/dist-packages (from dm-sonnet) (0.8.7)\n","Requirement already satisfied: dm-tree>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from dm-sonnet) (0.1.5)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from dm-sonnet) (1.12.1)\n","Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from dm-sonnet) (1.19.4)\n","Installing collected packages: dm-sonnet\n","Successfully installed dm-sonnet-2.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uLIPfeK6e7Se"},"source":["from __future__ import absolute_import\r\n","from __future__ import division\r\n","from __future__ import print_function\r\n","\r\n","import sonnet as snt\r\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MeS4yXuHfBuq"},"source":["class Unit3D(snt.Module):\r\n","  \"\"\"Basic unit containing Conv3D + BatchNorm + non-linearity.\"\"\"\r\n","\r\n","  def __init__(self, output_channels,\r\n","               kernel_shape=(1, 1, 1),\r\n","               stride=(1, 1, 1),\r\n","               activation_fn=tf.nn.relu,\r\n","               use_batch_norm=True,\r\n","               use_bias=False,\r\n","               name='unit_3d'):\r\n","    \"\"\"Initializes Unit3D module.\"\"\"\r\n","    super(Unit3D, self).__init__(name=name)\r\n","    self._output_channels = output_channels\r\n","    self._kernel_shape = kernel_shape\r\n","    self._stride = stride\r\n","    self._use_batch_norm = use_batch_norm\r\n","    self._activation_fn = activation_fn\r\n","    self._use_bias = use_bias\r\n","\r\n","  def _build(self, inputs, is_training):\r\n","    \"\"\"Connects the module to inputs.\r\n","\r\n","    Args:\r\n","      inputs: Inputs to the Unit3D component.\r\n","      is_training: whether to use training mode for snt.BatchNorm (boolean).\r\n","\r\n","    Returns:\r\n","      Outputs from the module.\r\n","    \"\"\"\r\n","    net = snt.Conv3D(output_channels=self._output_channels,\r\n","                     kernel_shape=self._kernel_shape,\r\n","                     stride=self._stride,\r\n","                     padding=snt.SAME,\r\n","                     use_bias=self._use_bias)(inputs)\r\n","    if self._use_batch_norm:\r\n","      bn = snt.BatchNorm()\r\n","      net = bn(net, is_training=is_training, test_local_stats=False)\r\n","    if self._activation_fn is not None:\r\n","      net = self._activation_fn(net)\r\n","    return net"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6oy5VuSkfViO"},"source":["class InceptionI3d(snt.Module):\r\n","  \"\"\"Inception-v1 I3D architecture.\r\n","\r\n","  The model is introduced in:\r\n","\r\n","    Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\r\n","    Joao Carreira, Andrew Zisserman\r\n","    https://arxiv.org/pdf/1705.07750v1.pdf.\r\n","\r\n","  See also the Inception architecture, introduced in:\r\n","\r\n","    Going deeper with convolutions\r\n","    Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,\r\n","    Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich.\r\n","    http://arxiv.org/pdf/1409.4842v1.pdf.\r\n","  \"\"\"\r\n","\r\n","  # Endpoints of the model in order. During construction, all the endpoints up\r\n","  # to a designated `final_endpoint` are returned in a dictionary as the\r\n","  # second return value.\r\n","  VALID_ENDPOINTS = (\r\n","      'Conv3d_1a_7x7',\r\n","      'MaxPool3d_2a_3x3',\r\n","      'Conv3d_2b_1x1',\r\n","      'Conv3d_2c_3x3',\r\n","      'MaxPool3d_3a_3x3',\r\n","      'Mixed_3b',\r\n","      'Mixed_3c',\r\n","      'MaxPool3d_4a_3x3',\r\n","      'Mixed_4b',\r\n","      'Mixed_4c',\r\n","      'Mixed_4d',\r\n","      'Mixed_4e',\r\n","      'Mixed_4f',\r\n","      'MaxPool3d_5a_2x2',\r\n","      'Mixed_5b',\r\n","      'Mixed_5c',\r\n","      'Logits',\r\n","      'Predictions',\r\n","  )\r\n","\r\n","  def __init__(self, num_classes=400, spatial_squeeze=True,\r\n","               final_endpoint='Logits', name='inception_i3d'):\r\n","    \"\"\"Initializes I3D model instance.\r\n","\r\n","    Args:\r\n","      num_classes: The number of outputs in the logit layer (default 400, which\r\n","          matches the Kinetics dataset).\r\n","      spatial_squeeze: Whether to squeeze the spatial dimensions for the logits\r\n","          before returning (default True).\r\n","      final_endpoint: The model contains many possible endpoints.\r\n","          `final_endpoint` specifies the last endpoint for the model to be built\r\n","          up to. In addition to the output at `final_endpoint`, all the outputs\r\n","          at endpoints up to `final_endpoint` will also be returned, in a\r\n","          dictionary. `final_endpoint` must be one of\r\n","          InceptionI3d.VALID_ENDPOINTS (default 'Logits').\r\n","      name: A string (optional). The name of this module.\r\n","\r\n","    Raises:\r\n","      ValueError: if `final_endpoint` is not recognized.\r\n","    \"\"\"\r\n","\r\n","    if final_endpoint not in self.VALID_ENDPOINTS:\r\n","      raise ValueError('Unknown final endpoint %s' % final_endpoint)\r\n","\r\n","    super(InceptionI3d, self).__init__(name=name)\r\n","    self._num_classes = num_classes\r\n","    self._spatial_squeeze = spatial_squeeze\r\n","    self._final_endpoint = final_endpoint\r\n","\r\n","  def _build(self, inputs, is_training, dropout_keep_prob=1.0):\r\n","    \"\"\"Connects the model to inputs.\r\n","\r\n","    Args:\r\n","      inputs: Inputs to the model, which should have dimensions\r\n","          `batch_size` x `num_frames` x 224 x 224 x `num_channels`.\r\n","      is_training: whether to use training mode for snt.BatchNorm (boolean).\r\n","      dropout_keep_prob: Probability for the tf.nn.dropout layer (float in\r\n","          [0, 1)).\r\n","\r\n","    Returns:\r\n","      A tuple consisting of:\r\n","        1. Network output at location `self._final_endpoint`.\r\n","        2. Dictionary containing all endpoints up to `self._final_endpoint`,\r\n","           indexed by endpoint name.\r\n","\r\n","    Raises:\r\n","      ValueError: if `self._final_endpoint` is not recognized.\r\n","    \"\"\"\r\n","    if self._final_endpoint not in self.VALID_ENDPOINTS:\r\n","      raise ValueError('Unknown final endpoint %s' % self._final_endpoint)\r\n","\r\n","    net = inputs\r\n","    end_points = {}\r\n","    end_point = 'Conv3d_1a_7x7'\r\n","    net = Unit3D(output_channels=64, kernel_shape=[7, 7, 7],\r\n","                 stride=[2, 2, 2], name=end_point)(net, is_training=is_training)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","    end_point = 'MaxPool3d_2a_3x3'\r\n","    net = tf.nn.max_pool3d(net, ksize=[1, 1, 3, 3, 1], strides=[1, 1, 2, 2, 1],\r\n","                           padding=snt.SAME, name=end_point)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","    end_point = 'Conv3d_2b_1x1'\r\n","    net = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\r\n","                 name=end_point)(net, is_training=is_training)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","    end_point = 'Conv3d_2c_3x3'\r\n","    net = Unit3D(output_channels=192, kernel_shape=[3, 3, 3],\r\n","                 name=end_point)(net, is_training=is_training)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","    end_point = 'MaxPool3d_3a_3x3'\r\n","    net = tf.nn.max_pool3d(net, ksize=[1, 1, 3, 3, 1], strides=[1, 1, 2, 2, 1],\r\n","                           padding=snt.SAME, name=end_point)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","\r\n","    end_point = 'Mixed_3b'\r\n","    with tf.compat.v1.variable_scope(end_point):\r\n","      with tf.compat.v1.variable_scope('Branch_0'):\r\n","        branch_0 = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_1'):\r\n","        branch_1 = Unit3D(output_channels=96, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_1 = Unit3D(output_channels=128, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_1,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_2'):\r\n","        branch_2 = Unit3D(output_channels=16, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_2 = Unit3D(output_channels=32, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_2,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_3'):\r\n","        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\r\n","                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\r\n","                                    name='MaxPool3d_0a_3x3')\r\n","        branch_3 = Unit3D(output_channels=32, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0b_1x1')(branch_3,\r\n","                                                is_training=is_training)\r\n","\r\n","      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","\r\n","    end_point = 'Mixed_3c'\r\n","    with tf.compat.v1.variable_scope(end_point):\r\n","      with tf.compat.v1.variable_scope('Branch_0'):\r\n","        branch_0 = Unit3D(output_channels=128, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_1'):\r\n","        branch_1 = Unit3D(output_channels=128, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_1 = Unit3D(output_channels=192, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_1,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_2'):\r\n","        branch_2 = Unit3D(output_channels=32, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_2 = Unit3D(output_channels=96, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_2,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_3'):\r\n","        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\r\n","                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\r\n","                                    name='MaxPool3d_0a_3x3')\r\n","        branch_3 = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0b_1x1')(branch_3,\r\n","                                                is_training=is_training)\r\n","      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","\r\n","    end_point = 'MaxPool3d_4a_3x3'\r\n","    net = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1], strides=[1, 2, 2, 2, 1],\r\n","                           padding=snt.SAME, name=end_point)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","\r\n","    end_point = 'Mixed_4b'\r\n","    with tf.compat.v1.variable_scope(end_point):\r\n","      with tf.compat.v1.variable_scope('Branch_0'):\r\n","        branch_0 = Unit3D(output_channels=192, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_1'):\r\n","        branch_1 = Unit3D(output_channels=96, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_1 = Unit3D(output_channels=208, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_1,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_2'):\r\n","        branch_2 = Unit3D(output_channels=16, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_2 = Unit3D(output_channels=48, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_2,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_3'):\r\n","        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\r\n","                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\r\n","                                    name='MaxPool3d_0a_3x3')\r\n","        branch_3 = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0b_1x1')(branch_3,\r\n","                                                is_training=is_training)\r\n","      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","\r\n","    end_point = 'Mixed_4c'\r\n","    with tf.compat.v1.variable_scope(end_point):\r\n","      with tf.compat.v1.variable_scope('Branch_0'):\r\n","        branch_0 = Unit3D(output_channels=160, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_1'):\r\n","        branch_1 = Unit3D(output_channels=112, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_1 = Unit3D(output_channels=224, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_1,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_2'):\r\n","        branch_2 = Unit3D(output_channels=24, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_2 = Unit3D(output_channels=64, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_2,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_3'):\r\n","        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\r\n","                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\r\n","                                    name='MaxPool3d_0a_3x3')\r\n","        branch_3 = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0b_1x1')(branch_3,\r\n","                                                is_training=is_training)\r\n","      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","\r\n","    end_point = 'Mixed_4d'\r\n","    with tf.compat.v1.variable_scope(end_point):\r\n","      with tf.compat.v1.variable_scope('Branch_0'):\r\n","        branch_0 = Unit3D(output_channels=128, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_1'):\r\n","        branch_1 = Unit3D(output_channels=128, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_1 = Unit3D(output_channels=256, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_1,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_2'):\r\n","        branch_2 = Unit3D(output_channels=24, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_2 = Unit3D(output_channels=64, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_2,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_3'):\r\n","        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\r\n","                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\r\n","                                    name='MaxPool3d_0a_3x3')\r\n","        branch_3 = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0b_1x1')(branch_3,\r\n","                                                is_training=is_training)\r\n","      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","\r\n","    end_point = 'Mixed_4e'\r\n","    with tf.compat.v1.variable_scope(end_point):\r\n","      with tf.compat.v1.variable_scope('Branch_0'):\r\n","        branch_0 = Unit3D(output_channels=112, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_1'):\r\n","        branch_1 = Unit3D(output_channels=144, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_1 = Unit3D(output_channels=288, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_1,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_2'):\r\n","        branch_2 = Unit3D(output_channels=32, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_2 = Unit3D(output_channels=64, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_2,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_3'):\r\n","        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\r\n","                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\r\n","                                    name='MaxPool3d_0a_3x3')\r\n","        branch_3 = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0b_1x1')(branch_3,\r\n","                                                is_training=is_training)\r\n","      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","\r\n","    end_point = 'Mixed_4f'\r\n","    with tf.compat.v1.variable_scope(end_point):\r\n","      with tf.compat.v1.variable_scope('Branch_0'):\r\n","        branch_0 = Unit3D(output_channels=256, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_1'):\r\n","        branch_1 = Unit3D(output_channels=160, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_1 = Unit3D(output_channels=320, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_1,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_2'):\r\n","        branch_2 = Unit3D(output_channels=32, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_2 = Unit3D(output_channels=128, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_2,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_3'):\r\n","        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\r\n","                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\r\n","                                    name='MaxPool3d_0a_3x3')\r\n","        branch_3 = Unit3D(output_channels=128, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0b_1x1')(branch_3,\r\n","                                                is_training=is_training)\r\n","      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","\r\n","    end_point = 'MaxPool3d_5a_2x2'\r\n","    net = tf.nn.max_pool3d(net, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1],\r\n","                           padding=snt.SAME, name=end_point)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","\r\n","    end_point = 'Mixed_5b'\r\n","    with tf.compat.v1.variable_scope(end_point):\r\n","      with tf.compat.v1.variable_scope('Branch_0'):\r\n","        branch_0 = Unit3D(output_channels=256, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_1'):\r\n","        branch_1 = Unit3D(output_channels=160, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_1 = Unit3D(output_channels=320, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_1,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_2'):\r\n","        branch_2 = Unit3D(output_channels=32, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_2 = Unit3D(output_channels=128, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0a_3x3')(branch_2,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_3'):\r\n","        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\r\n","                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\r\n","                                    name='MaxPool3d_0a_3x3')\r\n","        branch_3 = Unit3D(output_channels=128, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0b_1x1')(branch_3,\r\n","                                                is_training=is_training)\r\n","      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","\r\n","    end_point = 'Mixed_5c'\r\n","    with tf.compat.v1.variable_scope(end_point):\r\n","      with tf.compat.v1.variable_scope('Branch_0'):\r\n","        branch_0 = Unit3D(output_channels=384, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_1'):\r\n","        branch_1 = Unit3D(output_channels=192, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_1 = Unit3D(output_channels=384, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_1,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_2'):\r\n","        branch_2 = Unit3D(output_channels=48, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\r\n","        branch_2 = Unit3D(output_channels=128, kernel_shape=[3, 3, 3],\r\n","                          name='Conv3d_0b_3x3')(branch_2,\r\n","                                                is_training=is_training)\r\n","      with tf.compat.v1.variable_scope('Branch_3'):\r\n","        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\r\n","                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\r\n","                                    name='MaxPool3d_0a_3x3')\r\n","        branch_3 = Unit3D(output_channels=128, kernel_shape=[1, 1, 1],\r\n","                          name='Conv3d_0b_1x1')(branch_3,\r\n","                                                is_training=is_training)\r\n","      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\r\n","    end_points[end_point] = net\r\n","    if self._final_endpoint == end_point: return net, end_points\r\n","\r\n","    end_point = 'Logits'\r\n","    with tf.compat.v1.variable_scope(end_point):\r\n","      # net = tf.nn.avg_pool3d(net, ksize=[1, 2, 7, 7, 1], \r\n","      net = tf.nn.avg_pool3d(net, ksize=[1, 1, 7, 7, 1], \r\n","      strides=[1, 1, 1, 1, 1], padding=snt.VALID)\r\n","      print(net) # Tensor(\"Flow/inception_i3d/Logits/AvgPool3D:0\", shape=(1, 4, 1, 1, 1024), dtype=float32)\r\n","      # we need to store this net \r\n","      \r\n","      # change \r\n","      end_points['avg_pool3d'] = net #change according \r\n","      \r\n","      net = tf.nn.dropout(net, dropout_keep_prob)\r\n","      logits = Unit3D(output_channels=self._num_classes,\r\n","                      kernel_shape=[1, 1, 1],\r\n","                      activation_fn=None,\r\n","                      use_batch_norm=False,\r\n","                      use_bias=True,\r\n","                      name='Conv3d_0c_1x1')(net, is_training=is_training)\r\n","      if self._spatial_squeeze:\r\n","        logits = tf.squeeze(logits, [2, 3], name='SpatialSqueeze')\r\n","    averaged_logits = tf.reduce_mean(logits, axis=1)\r\n","    end_points[end_point] = averaged_logits\r\n","    \r\n","    if self._final_endpoint == end_point: return averaged_logits, end_points\r\n","    \r\n","\r\n","    end_point = 'Predictions'\r\n","    predictions = tf.nn.softmax(averaged_logits)\r\n","    end_points[end_point] = predictions\r\n","    return predictions, end_points"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rTIDQuvxfdAN"},"source":["net = InceptionI3d(400, spatial_squeeze=True, final_endpoint='Logits')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bxw2jp-8h36e"},"source":["recover the weights from pretrained checkpoints"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GA-luj1ch0G8","executionInfo":{"elapsed":730,"status":"ok","timestamp":1608525548070,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"},"user_tz":300},"outputId":"fa70adf9-7dcd-4128-82a9-a65f942d7924"},"source":["tf.compat.v1.global_variables()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":166},"id":"Xcq45YY_jqaG","executionInfo":{"elapsed":471,"status":"error","timestamp":1608525300417,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"},"user_tz":300},"outputId":"498986e8-0acf-46de-cc88-e07e0a4733ee"},"source":["net.load_weights('/content/drive/MyDrive/rgb_i3d_checkpoint')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-4e290f80d7dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/rgb_i3d_checkpoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'InceptionI3d' object has no attribute 'load_weights'"]}]},{"cell_type":"markdown","metadata":{"id":"LGhrawx5IzPX"},"source":["# **get extracted features**"]},{"cell_type":"code","metadata":{"id":"DLCvlqhRkAwT","executionInfo":{"status":"ok","timestamp":1608610881958,"user_tz":300,"elapsed":1158,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["import os\r\n","from tqdm import tqdm "],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"yC1TnCgiI3_P"},"source":["files = os.listdir('/content/drive/MyDrive/GIPHY_rgb_features')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-OEt-mQaJL-k","executionInfo":{"elapsed":283,"status":"ok","timestamp":1608585293728,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"},"user_tz":300},"outputId":"f57e0267-3fb7-4042-9e0f-760da263a3ab"},"source":["len(files)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["21424"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"Ym_FCKKGJ64e"},"source":["demo_file = files[10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cCiRZ0oFKDWB"},"source":["feature = np.load('/content/drive/MyDrive/GIPHY_rgb_features/' + demo_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WfHQ7J2uKN8w","executionInfo":{"elapsed":130,"status":"ok","timestamp":1608585414408,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"},"user_tz":300},"outputId":"0106d7c2-85ad-4a3f-c011-27f1966767b2"},"source":["feature.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 1024)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oOg5yHFqKRqa","executionInfo":{"elapsed":6440712,"status":"ok","timestamp":1608594280727,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"},"user_tz":300},"outputId":"8482b832-4b53-4697-c800-c487a599dae6"},"source":["features = {}\r\n","for f in tqdm(files):\r\n","    feature = np.load('/content/drive/MyDrive/GIPHY_rgb_features/' + f)\r\n","    features[f] = feature"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 21424/21424 [2:24:45<00:00,  2.47it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"nyWZ66G3LE1Z"},"source":["import pickle\r\n","with open('/content/drive/MyDrive/features.pickle', 'wb') as handle:\r\n","    pickle.dump(features, handle, protocol=pickle.HIGHEST_PROTOCOL)\r\n","\r\n","# with open('filename.pickle', 'rb') as handle:\r\n","#     b = pickle.load(handle)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XZAsvnntZYJd"},"source":["# **load features from drive**"]},{"cell_type":"code","metadata":{"id":"7clFjmqKZc8Y","executionInfo":{"status":"ok","timestamp":1608610898568,"user_tz":300,"elapsed":8519,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["import pickle\r\n","with open('/content/drive/MyDrive/features.pickle', 'rb') as handle:\r\n","    features = pickle.load(handle)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"scVKOmZJTlQZ"},"source":["# **pad the sequence to the same length**"]},{"cell_type":"code","metadata":{"id":"yYNeK-r1TpS8","executionInfo":{"status":"ok","timestamp":1608610902437,"user_tz":300,"elapsed":1207,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["seqs = features.values()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXVJJ-zQTplr","executionInfo":{"status":"ok","timestamp":1608610904532,"user_tz":300,"elapsed":1292,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["l = [len(seq) for seq in seqs]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Le1TIKUcdBRz","executionInfo":{"status":"ok","timestamp":1608610905947,"user_tz":300,"elapsed":1662,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":386},"id":"w-AnhheFdGKb","executionInfo":{"status":"ok","timestamp":1608610907981,"user_tz":300,"elapsed":2073,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"1d82dfe5-19cb-41a7-f401-3a313391997f"},"source":["sns.displot(l)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<seaborn.axisgrid.FacetGrid at 0x7fc780a0f470>"]},"metadata":{"tags":[]},"execution_count":9},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 360x360 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"id":"OvQfYbC0dQf8","executionInfo":{"status":"ok","timestamp":1608610911184,"user_tz":300,"elapsed":1253,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"766223e1-3007-4e86-8083-d0e812b27a94"},"source":["sns.boxplot(l)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fc78e6d6208>"]},"metadata":{"tags":[]},"execution_count":10},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"vlubifQYZx_1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608610920510,"user_tz":300,"elapsed":1091,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"a8fda995-d444-413a-cf7f-6d7703a02d02"},"source":["max(l)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["42"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"AtRq3yCYcE39","executionInfo":{"status":"ok","timestamp":1608610924340,"user_tz":300,"elapsed":1677,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["for f in features.keys():\n","    if len(features[f]) >= 10:\n","        features[f] = features[f][:10]\n","    else:\n","        features[f] = np.concatenate((features[f], np.zeros((10-features[f].shape[0], 1024))))"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"kKgKe3W9d-i6","executionInfo":{"status":"ok","timestamp":1608610926592,"user_tz":300,"elapsed":1082,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["demo = np.array(list(features.values()))"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFobw5t9eG3i","executionInfo":{"status":"ok","timestamp":1608610928233,"user_tz":300,"elapsed":760,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["df2 = pd.DataFrame({'content': list(features.keys()), 'features_timesteps': list(features.values())})"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1qx4rkkfV7_","executionInfo":{"status":"ok","timestamp":1608610929921,"user_tz":300,"elapsed":799,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["df2['content'] = df2['content'].apply(lambda s: s[:s.index('.')])"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"lq6CXpA_fqnX","executionInfo":{"status":"ok","timestamp":1608610933792,"user_tz":300,"elapsed":872,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"d4e15ed2-289f-4f25-8e97-c4598488cfb8"},"source":["df2.head()"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>features_timesteps</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3orif2X665FMqzGEdq</td>\n","      <td>[[0.3025616705417633, 0.09759683161973953, 0.0...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>vuZeED6SoCN8MbLZq8</td>\n","      <td>[[0.5516777038574219, 0.5094824433326721, 0.21...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>l3vRjQtRTdY3GacGQ</td>\n","      <td>[[0.22382314503192902, 0.0, 0.1331664770841598...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NYEAFHB94PZQI</td>\n","      <td>[[0.10112542659044266, 0.06395655125379562, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>xUOwV7IC3267zT9iBW</td>\n","      <td>[[0.43979328870773315, 0.11720772832632065, 0....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              content                                 features_timesteps\n","0  3orif2X665FMqzGEdq  [[0.3025616705417633, 0.09759683161973953, 0.0...\n","1  vuZeED6SoCN8MbLZq8  [[0.5516777038574219, 0.5094824433326721, 0.21...\n","2   l3vRjQtRTdY3GacGQ  [[0.22382314503192902, 0.0, 0.1331664770841598...\n","3       NYEAFHB94PZQI  [[0.10112542659044266, 0.06395655125379562, 0....\n","4  xUOwV7IC3267zT9iBW  [[0.43979328870773315, 0.11720772832632065, 0...."]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"o86jCQkTPylS"},"source":["# **create a dataframe used as a training data set**"]},{"cell_type":"code","metadata":{"id":"kLsBrNXpL5hQ","executionInfo":{"status":"ok","timestamp":1608613000221,"user_tz":300,"elapsed":1647,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["subset = df[['content','anger', 'fear', 'joy', 'sadness']]\r\n","trainset = subset.merge(df2, on='content', how='inner')"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"S8ZlyEYwy_AM","executionInfo":{"status":"ok","timestamp":1608613013971,"user_tz":300,"elapsed":718,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"187c3bd6-d2d9-4acd-cc64-668d4972c3ac"},"source":["trainset.head()"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>anger</th>\n","      <th>fear</th>\n","      <th>joy</th>\n","      <th>sadness</th>\n","      <th>features_timesteps</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5h47LBNpbb6TAvl41O</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>[[0.18471205234527588, 0.024927252903580666, 0...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>N4K0mbaJtwLgQ</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[[0.22143247723579407, 0.05100086331367493, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>moXqsEVbHOQtG</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>[[0.04298821836709976, 0.07614751905202866, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>l2JJHiitHbK0hnbXO</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>[[0.11309566348791122, 0.09070558845996857, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3oEduQ3FsAU0YD1Gec</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>[[0.24229487776756287, 0.006197239272296429, 0...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              content  ...                                 features_timesteps\n","0  5h47LBNpbb6TAvl41O  ...  [[0.18471205234527588, 0.024927252903580666, 0...\n","1       N4K0mbaJtwLgQ  ...  [[0.22143247723579407, 0.05100086331367493, 0....\n","2       moXqsEVbHOQtG  ...  [[0.04298821836709976, 0.07614751905202866, 0....\n","3   l2JJHiitHbK0hnbXO  ...  [[0.11309566348791122, 0.09070558845996857, 0....\n","4  3oEduQ3FsAU0YD1Gec  ...  [[0.24229487776756287, 0.006197239272296429, 0...\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zCb4J7Avi-EC","executionInfo":{"status":"ok","timestamp":1608613018053,"user_tz":300,"elapsed":1304,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"53581bed-fc07-4c62-d578-f5cec5463cc3"},"source":["print(len(trainset), len(df2), len(subset))"],"execution_count":41,"outputs":[{"output_type":"stream","text":["12591 21424 19076\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2hOOxrW_yvHx","executionInfo":{"status":"ok","timestamp":1608612985381,"user_tz":300,"elapsed":736,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"b715297a-8280-4390-8177-05c1eaddc03f"},"source":["trainset.isnull().sum()"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["content                  0\n","anger                    0\n","fear                     0\n","joy                      0\n","sadness                  0\n","features_timesteps    6485\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"vGb8bOPViCEj","executionInfo":{"status":"ok","timestamp":1608610951807,"user_tz":300,"elapsed":3108,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["subset.to_csv('/content/drive/MyDrive/lavender_CV_training_dataset.csv')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"NdRJbkWeQzQb","executionInfo":{"status":"ok","timestamp":1608610955761,"user_tz":300,"elapsed":790,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["from sklearn.model_selection import train_test_split\r\n","train, test = train_test_split(trainset, test_size = 0.3, shuffle=True)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WG9VjHVtjtzS","executionInfo":{"status":"ok","timestamp":1608610957962,"user_tz":300,"elapsed":1276,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"a666de33-8ef8-45f7-bc57-e112e378e07e"},"source":["print(train.shape, test.shape)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["(8813, 6) (3778, 6)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hurGj3jjjy6C","executionInfo":{"status":"ok","timestamp":1608610966726,"user_tz":300,"elapsed":1147,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["train_x = np.array(list(train.features_timesteps.values))\n","train_y = np.array(list(train[['anger', 'fear', 'joy', 'sadness']].values))\n","\n","test_x = np.array(list(test.features_timesteps.values))\n","test_y = np.array(list(test[['anger', 'fear', 'joy', 'sadness']].values))"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"smKb9bBERXm-"},"source":["# **Try to build a NN using LSTM**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6uAyyh-rIUI","executionInfo":{"status":"ok","timestamp":1608611015730,"user_tz":300,"elapsed":45298,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"20338d0f-5bc6-4897-fb7e-8d0a663acee1"},"source":["!pip install tensorflow-gpu"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/aa/ae64be5acaac9055329289e6bfd54c1efa28bfe792f9021cea495fe2b89d/tensorflow_gpu-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl (394.7MB)\n","\u001b[K     |████████████████████████████████| 394.7MB 43kB/s \n","\u001b[?25hRequirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.4.0)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.32.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.4.3)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.19.4)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.4.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.36.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (3.3.3)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.17.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (50.3.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.4.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (2.23.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.7.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (1.3.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2020.12.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.4.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (3.1.0)\n","Installing collected packages: tensorflow-gpu\n","Successfully installed tensorflow-gpu-2.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nNGmdldkRXEa","executionInfo":{"status":"ok","timestamp":1608611049066,"user_tz":300,"elapsed":2530,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["from tensorflow.keras.layers import * \r\n","from tensorflow.keras.models import *"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"xtal6_D0SvEF","executionInfo":{"status":"ok","timestamp":1608611280970,"user_tz":300,"elapsed":1299,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["i = Input(shape = (10, 1024))\r\n","x =LSTM(128, return_sequences=False, return_state=False)(i)\r\n","x = Dense(32, activation='relu')(x)\r\n","o = Dense(4, activation='sigmoid')(x)\r\n","model = Model(i, o)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7rJQ5mrqtEhE","executionInfo":{"status":"ok","timestamp":1608611290699,"user_tz":300,"elapsed":1234,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"3d6ac517-991a-4653-8418-e451b8929621"},"source":["model.summary()"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 10, 1024)]        0         \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 128)               590336    \n","_________________________________________________________________\n","dense (Dense)                (None, 32)                4128      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4)                 132       \n","=================================================================\n","Total params: 594,596\n","Trainable params: 594,596\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9-VAI7MyTcG0","executionInfo":{"status":"ok","timestamp":1608611308551,"user_tz":300,"elapsed":1244,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}}},"source":["model.compile(loss='binary_crossentropy', optimizer='RMSprop')"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"NtB66CjuTkbb","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1608612555535,"user_tz":300,"elapsed":1090657,"user":{"displayName":"Zhounan Li","photoUrl":"","userId":"12163187697439231323"}},"outputId":"7cfd278b-c08e-423d-bb87-fb9a34edeb64"},"source":["history = model.fit(train_x, train_y, batch_size=16, epochs=200, verbose=1, validation_data=(test_x, test_y), validation_batch_size=16)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.4505 - val_loss: 0.4427\n","Epoch 2/200\n","551/551 [==============================] - 13s 23ms/step - loss: 0.4319 - val_loss: 0.4350\n","Epoch 3/200\n","551/551 [==============================] - 13s 23ms/step - loss: 0.4127 - val_loss: 0.4374\n","Epoch 4/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.3921 - val_loss: 0.4331\n","Epoch 5/200\n","551/551 [==============================] - 13s 23ms/step - loss: 0.3659 - val_loss: 0.4892\n","Epoch 6/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.3368 - val_loss: 0.4926\n","Epoch 7/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.3082 - val_loss: 0.4636\n","Epoch 8/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.2753 - val_loss: 0.5892\n","Epoch 9/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.2427 - val_loss: 0.5615\n","Epoch 10/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.2133 - val_loss: 0.5766\n","Epoch 11/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.1860 - val_loss: 0.6318\n","Epoch 12/200\n","551/551 [==============================] - 13s 23ms/step - loss: 0.1617 - val_loss: 0.8283\n","Epoch 13/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.1432 - val_loss: 0.7039\n","Epoch 14/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.1265 - val_loss: 0.8256\n","Epoch 15/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.1083 - val_loss: 0.9008\n","Epoch 16/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0967 - val_loss: 0.9104\n","Epoch 17/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0872 - val_loss: 0.9682\n","Epoch 18/200\n","551/551 [==============================] - 14s 25ms/step - loss: 0.0785 - val_loss: 1.0133\n","Epoch 19/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0736 - val_loss: 1.0440\n","Epoch 20/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0642 - val_loss: 1.1172\n","Epoch 21/200\n","551/551 [==============================] - 14s 25ms/step - loss: 0.0577 - val_loss: 1.1915\n","Epoch 22/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0556 - val_loss: 1.2686\n","Epoch 23/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0528 - val_loss: 1.2891\n","Epoch 24/200\n","551/551 [==============================] - 13s 23ms/step - loss: 0.0469 - val_loss: 1.2723\n","Epoch 25/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0459 - val_loss: 1.3732\n","Epoch 26/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0419 - val_loss: 1.2426\n","Epoch 27/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0399 - val_loss: 1.4271\n","Epoch 28/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0378 - val_loss: 1.5589\n","Epoch 29/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0363 - val_loss: 1.6874\n","Epoch 30/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0355 - val_loss: 1.4700\n","Epoch 31/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0306 - val_loss: 1.6190\n","Epoch 32/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0322 - val_loss: 1.5466\n","Epoch 33/200\n","551/551 [==============================] - 13s 23ms/step - loss: 0.0324 - val_loss: 1.5686\n","Epoch 34/200\n","551/551 [==============================] - 13s 23ms/step - loss: 0.0323 - val_loss: 1.5778\n","Epoch 35/200\n","551/551 [==============================] - 13s 23ms/step - loss: 0.0288 - val_loss: 1.8780\n","Epoch 36/200\n","551/551 [==============================] - 13s 23ms/step - loss: 0.0301 - val_loss: 1.5989\n","Epoch 37/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0291 - val_loss: 1.6689\n","Epoch 38/200\n","551/551 [==============================] - 13s 23ms/step - loss: 0.0268 - val_loss: 1.7144\n","Epoch 39/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0223 - val_loss: 1.7816\n","Epoch 40/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0280 - val_loss: 1.6961\n","Epoch 41/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0269 - val_loss: 2.0471\n","Epoch 42/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0265 - val_loss: 1.7193\n","Epoch 43/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0229 - val_loss: 1.7919\n","Epoch 44/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0218 - val_loss: 2.0725\n","Epoch 45/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0251 - val_loss: 1.9484\n","Epoch 46/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0251 - val_loss: 1.6621\n","Epoch 47/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0200 - val_loss: 2.0176\n","Epoch 48/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0205 - val_loss: 1.9485\n","Epoch 49/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0226 - val_loss: 1.9045\n","Epoch 50/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0238 - val_loss: 1.9451\n","Epoch 51/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0197 - val_loss: 2.0522\n","Epoch 52/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0198 - val_loss: 1.9218\n","Epoch 53/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0192 - val_loss: 2.0899\n","Epoch 54/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0221 - val_loss: 1.9853\n","Epoch 55/200\n","551/551 [==============================] - 14s 26ms/step - loss: 0.0220 - val_loss: 1.9820\n","Epoch 56/200\n","551/551 [==============================] - 15s 27ms/step - loss: 0.0237 - val_loss: 1.6937\n","Epoch 57/200\n","551/551 [==============================] - 14s 26ms/step - loss: 0.0219 - val_loss: 2.1037\n","Epoch 58/200\n","551/551 [==============================] - 15s 26ms/step - loss: 0.0201 - val_loss: 2.0551\n","Epoch 59/200\n","551/551 [==============================] - 14s 26ms/step - loss: 0.0195 - val_loss: 2.3196\n","Epoch 60/200\n","551/551 [==============================] - 14s 25ms/step - loss: 0.0216 - val_loss: 2.1120\n","Epoch 61/200\n","551/551 [==============================] - 14s 25ms/step - loss: 0.0206 - val_loss: 2.1555\n","Epoch 62/200\n","551/551 [==============================] - 13s 24ms/step - loss: 0.0206 - val_loss: 2.2704\n","Epoch 63/200\n","551/551 [==============================] - 14s 25ms/step - loss: 0.0203 - val_loss: 2.2131\n","Epoch 64/200\n","551/551 [==============================] - 14s 25ms/step - loss: 0.0198 - val_loss: 2.0343\n","Epoch 65/200\n","551/551 [==============================] - 14s 25ms/step - loss: 0.0193 - val_loss: 2.0607\n","Epoch 66/200\n","551/551 [==============================] - 14s 25ms/step - loss: 0.0223 - val_loss: 2.0859\n","Epoch 67/200\n","551/551 [==============================] - 14s 26ms/step - loss: 0.0185 - val_loss: 2.2751\n","Epoch 68/200\n","551/551 [==============================] - 15s 27ms/step - loss: 0.0192 - val_loss: 2.3483\n","Epoch 69/200\n","551/551 [==============================] - 14s 26ms/step - loss: 0.0186 - val_loss: 2.2238\n","Epoch 70/200\n","551/551 [==============================] - 15s 26ms/step - loss: 0.0188 - val_loss: 2.3767\n","Epoch 71/200\n","551/551 [==============================] - 14s 26ms/step - loss: 0.0200 - val_loss: 1.8410\n","Epoch 72/200\n","551/551 [==============================] - 14s 26ms/step - loss: 0.0169 - val_loss: 2.5223\n","Epoch 73/200\n","551/551 [==============================] - 15s 27ms/step - loss: 0.0184 - val_loss: 2.2572\n","Epoch 74/200\n","551/551 [==============================] - 15s 26ms/step - loss: 0.0218 - val_loss: 2.2663\n","Epoch 75/200\n","551/551 [==============================] - 14s 26ms/step - loss: 0.0186 - val_loss: 2.1340\n","Epoch 76/200\n","551/551 [==============================] - 14s 26ms/step - loss: 0.0178 - val_loss: 2.2952\n","Epoch 77/200\n","551/551 [==============================] - 14s 26ms/step - loss: 0.0164 - val_loss: 2.3892\n","Epoch 78/200\n","551/551 [==============================] - 14s 26ms/step - loss: 0.0177 - val_loss: 2.3242\n","Epoch 79/200\n","551/551 [==============================] - 14s 25ms/step - loss: 0.0140 - val_loss: 2.5393\n","Epoch 80/200\n","551/551 [==============================] - 14s 25ms/step - loss: 0.0177 - val_loss: 2.3300\n","Epoch 81/200\n","550/551 [============================>.] - ETA: 0s - loss: 0.0184"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-07ea6a08d3cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"YJNmZ4LGtmae"},"source":[""],"execution_count":null,"outputs":[]}]}